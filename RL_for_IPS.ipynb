{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aT_eRurZCT-g",
        "outputId": "fcdbe526-0bec-489d-b32a-77663febbb1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.9 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.9.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.5.2)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.4.1+cu121)\n",
            "Requirement already satisfied: scapy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.5.0)\n",
            "Requirement already satisfied: dpkt in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.9.8)\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.23.5)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9->-r requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9->-r requirements.txt (line 1)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9->-r requirements.txt (line 1)) (1.12)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9->-r requirements.txt (line 1)) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9->-r requirements.txt (line 1)) (1.64.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9->-r requirements.txt (line 1)) (3.11.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9->-r requirements.txt (line 1)) (2.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9->-r requirements.txt (line 1)) (1.1.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9->-r requirements.txt (line 1)) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9->-r requirements.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9->-r requirements.txt (line 1)) (24.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9->-r requirements.txt (line 1)) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9->-r requirements.txt (line 1)) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9->-r requirements.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9->-r requirements.txt (line 1)) (2.9.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9->-r requirements.txt (line 1)) (0.37.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9->-r requirements.txt (line 1)) (2.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9->-r requirements.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9->-r requirements.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 2)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym->-r requirements.txt (line 3)) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym->-r requirements.txt (line 3)) (0.0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (2024.6.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.9->-r requirements.txt (line 1)) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9->-r requirements.txt (line 1)) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9->-r requirements.txt (line 1)) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9->-r requirements.txt (line 1)) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9->-r requirements.txt (line 1)) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9->-r requirements.txt (line 1)) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 4)) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9->-r requirements.txt (line 1)) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9->-r requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9->-r requirements.txt (line 1)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9->-r requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9->-r requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9->-r requirements.txt (line 1)) (2024.8.30)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9->-r requirements.txt (line 1)) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9->-r requirements.txt (line 1)) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfw_hxCY86Ne",
        "outputId": "6964ac37-4bc4-484f-984e-df8a181341fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dpkt\n",
        "import socket\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import regularizers, layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Hyperparameters\n",
        "EPISODES = 1000  # Increased to allow more training\n",
        "EPSILON_START = 1.0\n",
        "EPSILON_MIN = 0.01\n",
        "EPSILON_DECAY = 0.995\n",
        "GAMMA = 0.95  # Discount factor (gamma) for future rewards\n",
        "BATCH_SIZE = 16\n",
        "MAX_STEPS_PER_EPISODE = 30\n",
        "LEARNING_RATE = 0.0001\n",
        "REPLAY_MEMORY_SIZE = 5000  # Cap the replay buffer to avoid infinite memory usage"
      ],
      "metadata": {
        "id": "Ka87r6r5DcsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"/content/drive/MyDrive/CICIDS2017/Friday-WorkingHours-Morning.pcap_ISCX.csv\")\n",
        "dataset.head()\n",
        "\n",
        "# Remove leading spaces from column names\n",
        "dataset.columns = dataset.columns.str.strip()\n",
        "\n",
        "# Feature selection\n",
        "features = dataset[['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets',\n",
        "                    'Total Length of Fwd Packets', 'Total Length of Bwd Packets',\n",
        "                    'Fwd Packet Length Mean', 'Bwd Packet Length Mean',\n",
        "                    'Flow IAT Mean', 'Flow IAT Std', 'Fwd IAT Mean']]\n",
        "\n",
        "# Label selection (malicious or benign traffic)\n",
        "labels = dataset['Label']\n",
        "\n",
        "# Feature normalization\n",
        "scaler = StandardScaler()\n",
        "features = scaler.fit_transform(features)\n",
        "\n",
        "# Convert labels to binary format (benign = 0, malicious = 1)\n",
        "labels = labels.apply(lambda x: 1 if 'malicious' in x.lower() else 0)\n",
        "\n",
        "# Combine features and labels to form the dataset\n",
        "data = list(zip(features, labels))"
      ],
      "metadata": {
        "id": "LZypCG0FDAKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Epsilon decay function for action exploration\n",
        "def epsilon_decay(episode, initial_epsilon=EPSILON_START, min_epsilon=EPSILON_MIN, decay_rate=EPSILON_DECAY):\n",
        "    return max(min_epsilon, initial_epsilon * (decay_rate ** episode))\n",
        "\n",
        "# Q-Network Definition ====================================\n",
        "\n",
        "# Define the Q-network model\n",
        "def create_q_model():\n",
        "    inputs = layers.Input(shape=(state_size,))\n",
        "    layer1 = layers.Dense(256, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(inputs)\n",
        "    layer2 = layers.Dense(256, activation=\"relu\")(layer1)\n",
        "    layer3 = layers.Dense(128, activation=\"relu\")(layer2)\n",
        "    action = layers.Dense(num_actions, activation=\"linear\")(layer3)\n",
        "    return tf.keras.Model(inputs=inputs, outputs=action)\n",
        "\n",
        "# Hyperparameters for the Q-network\n",
        "state_size = 10  # Based on the number of features\n",
        "num_actions = 3  # Actions: Allow, Block, Flag\n",
        "\n",
        "# Create and compile the Q-network model\n",
        "model = create_q_model()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), loss='mse')\n",
        "\n",
        "# Action Selection and Environment Interaction ====================================\n",
        "\n",
        "# Epsilon-greedy action selection\n",
        "def choose_action(state, epsilon):\n",
        "    if np.random.random() < epsilon:\n",
        "        return np.random.choice(num_actions)  # Random action (exploration)\n",
        "    else:\n",
        "        q_values = model.predict(np.expand_dims(state, axis=0), verbose=0)  # Predict action values\n",
        "        return np.argmax(q_values)  # Choose action with highest Q-value\n",
        "\n",
        "# Function to get the initial state from the dataset\n",
        "def get_initial_state(index=None):\n",
        "    if index is None:\n",
        "        index = np.random.randint(0, len(data))\n",
        "    state, label = data[index]\n",
        "    return state, label\n"
      ],
      "metadata": {
        "id": "cnbeA1OxCcei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute action and return the next state, reward, and done flag\n",
        "def execute_action(action, current_state, step):\n",
        "    next_state, label = get_initial_state()  # Get next state and its label (benign or malicious)\n",
        "\n",
        "    # Define reward structure\n",
        "    if action == 0:  # Allow\n",
        "        reward = -3 if label == 1 else 2  # Penalty for allowing malicious, reward for benign\n",
        "    elif action == 1:  # Block\n",
        "        reward = 3 if label == 1 else -1  # Reward for blocking malicious, penalty for false positive\n",
        "    else:  # Flag\n",
        "        reward = 0.5 if label == 1 else 0  # Small reward for flagging malicious, neutral for benign\n",
        "\n",
        "    done = (step >= MAX_STEPS_PER_EPISODE) or (np.random.rand() > 0.90)  # Properly end episodes\n",
        "    return next_state, reward, done"
      ],
      "metadata": {
        "id": "BYYcahFVENL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train the agent and visualize rewards\n",
        "def train_and_visualize(episodes):\n",
        "    rewards_per_episode = []\n",
        "    memory = []  # Replay memory to store experiences\n",
        "\n",
        "    for episode in range(episodes):\n",
        "        state, _ = get_initial_state()\n",
        "        total_reward = 0\n",
        "        done = False\n",
        "        step = 0\n",
        "        epsilon = epsilon_decay(episode)\n",
        "\n",
        "        print(f\"\\n==== Starting Episode {episode} ====\")\n",
        "\n",
        "        while not done and step < MAX_STEPS_PER_EPISODE:  # Limit the number of steps per episode\n",
        "            step += 1\n",
        "            action = choose_action(state, epsilon)\n",
        "            next_state, reward, done = execute_action(action, state, step)\n",
        "            total_reward += reward\n",
        "\n",
        "            # Store transition in memory (state, action, reward, next_state, done)\n",
        "            memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "            # Limit memory size to avoid infinite growth\n",
        "            if len(memory) > REPLAY_MEMORY_SIZE:\n",
        "                memory.pop(0)\n",
        "\n",
        "            # Train the model if we have enough experiences in memory\n",
        "            if len(memory) >= BATCH_SIZE:\n",
        "                # Randomly sample a batch from memory\n",
        "                batch = random.sample(memory, BATCH_SIZE)\n",
        "\n",
        "                # Separate each part of the batch into state, action, reward, etc.\n",
        "                states_b, actions_b, rewards_b, next_states_b, dones_b = zip(*batch)\n",
        "\n",
        "                # Convert each part to numpy arrays\n",
        "                states_b = np.array(states_b)\n",
        "                actions_b = np.array(actions_b)\n",
        "                rewards_b = np.array(rewards_b)\n",
        "                next_states_b = np.array(next_states_b)\n",
        "                dones_b = np.array(dones_b)\n",
        "\n",
        "                # Train the model using the batch\n",
        "                for i in range(BATCH_SIZE):\n",
        "                    next_q_values = model.predict(np.expand_dims(next_states_b[i], axis=0), verbose=0)\n",
        "                    max_next_q_value = np.max(next_q_values)  # Max Q-value for the next state\n",
        "\n",
        "                    # Calculate target Q-value\n",
        "                    target_q_value = rewards_b[i] + GAMMA * max_next_q_value * (not dones_b[i])\n",
        "\n",
        "                    # Predict Q-values for the current state and update the selected action's Q-value\n",
        "                    q_values = model.predict(np.expand_dims(states_b[i], axis=0), verbose=0)\n",
        "                    q_values[0][actions_b[i]] = target_q_value\n",
        "\n",
        "                    # Train the model on this step\n",
        "                    model.fit(np.expand_dims(states_b[i], axis=0), q_values, epochs=1, verbose=0)\n",
        "\n",
        "            # Move to the next state\n",
        "            state = next_state\n",
        "\n",
        "        # Force done if we hit the maximum step count\n",
        "        rewards_per_episode.append(total_reward)\n",
        "        print(f\"Total Reward for Episode {episode}: {total_reward}\")\n",
        "        print(f\"==== End of Episode {episode} ====\\n\")\n",
        "\n",
        "    # Plot the reward progress over episodes\n",
        "    plt.plot(rewards_per_episode)\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Total Reward\")\n",
        "    plt.title(\"Reward Progress Over Episodes\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "0eqb-to5EddJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the training process with batch learning\n",
        "train_and_visualize(EPISODES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5JFPI0FEOOM",
        "outputId": "f7890cff-3ae8-43ac-8282-b5b100c6bf3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==== Starting Episode 0 ====\n",
            "Total Reward for Episode 0: 0\n",
            "==== End of Episode 0 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 1 ====\n",
            "Total Reward for Episode 1: 5\n",
            "==== End of Episode 1 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 2 ====\n",
            "Total Reward for Episode 2: -4\n",
            "==== End of Episode 2 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 3 ====\n",
            "Total Reward for Episode 3: 1\n",
            "==== End of Episode 3 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 4 ====\n",
            "Total Reward for Episode 4: 2\n",
            "==== End of Episode 4 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 5 ====\n",
            "Total Reward for Episode 5: 5\n",
            "==== End of Episode 5 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 6 ====\n",
            "Total Reward for Episode 6: 5\n",
            "==== End of Episode 6 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 7 ====\n",
            "Total Reward for Episode 7: 5\n",
            "==== End of Episode 7 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 8 ====\n",
            "Total Reward for Episode 8: 4\n",
            "==== End of Episode 8 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 9 ====\n",
            "Total Reward for Episode 9: 4\n",
            "==== End of Episode 9 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 10 ====\n",
            "Total Reward for Episode 10: 5\n",
            "==== End of Episode 10 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 11 ====\n",
            "Total Reward for Episode 11: 1\n",
            "==== End of Episode 11 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 12 ====\n",
            "Total Reward for Episode 12: 3\n",
            "==== End of Episode 12 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 13 ====\n",
            "Total Reward for Episode 13: 2\n",
            "==== End of Episode 13 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 14 ====\n",
            "Total Reward for Episode 14: 5\n",
            "==== End of Episode 14 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 15 ====\n",
            "Total Reward for Episode 15: 8\n",
            "==== End of Episode 15 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 16 ====\n",
            "Total Reward for Episode 16: 4\n",
            "==== End of Episode 16 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 17 ====\n",
            "Total Reward for Episode 17: -1\n",
            "==== End of Episode 17 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 18 ====\n",
            "Total Reward for Episode 18: 1\n",
            "==== End of Episode 18 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 19 ====\n",
            "Total Reward for Episode 19: 0\n",
            "==== End of Episode 19 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 20 ====\n",
            "Total Reward for Episode 20: 2\n",
            "==== End of Episode 20 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 21 ====\n",
            "Total Reward for Episode 21: -1\n",
            "==== End of Episode 21 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 22 ====\n",
            "Total Reward for Episode 22: 12\n",
            "==== End of Episode 22 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 23 ====\n",
            "Total Reward for Episode 23: -1\n",
            "==== End of Episode 23 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 24 ====\n",
            "Total Reward for Episode 24: 6\n",
            "==== End of Episode 24 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 25 ====\n",
            "Total Reward for Episode 25: 3\n",
            "==== End of Episode 25 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 26 ====\n",
            "Total Reward for Episode 26: 6\n",
            "==== End of Episode 26 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 27 ====\n",
            "Total Reward for Episode 27: 1\n",
            "==== End of Episode 27 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 28 ====\n",
            "Total Reward for Episode 28: 13\n",
            "==== End of Episode 28 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 29 ====\n",
            "Total Reward for Episode 29: 18\n",
            "==== End of Episode 29 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 30 ====\n",
            "Total Reward for Episode 30: 20\n",
            "==== End of Episode 30 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 31 ====\n",
            "Total Reward for Episode 31: 3\n",
            "==== End of Episode 31 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 32 ====\n",
            "Total Reward for Episode 32: 4\n",
            "==== End of Episode 32 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 33 ====\n",
            "Total Reward for Episode 33: 0\n",
            "==== End of Episode 33 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 34 ====\n",
            "Total Reward for Episode 34: 2\n",
            "==== End of Episode 34 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 35 ====\n",
            "Total Reward for Episode 35: 6\n",
            "==== End of Episode 35 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 36 ====\n",
            "Total Reward for Episode 36: 11\n",
            "==== End of Episode 36 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 37 ====\n",
            "Total Reward for Episode 37: 1\n",
            "==== End of Episode 37 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 38 ====\n",
            "Total Reward for Episode 38: 10\n",
            "==== End of Episode 38 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 39 ====\n",
            "Total Reward for Episode 39: 20\n",
            "==== End of Episode 39 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 40 ====\n",
            "Total Reward for Episode 40: -1\n",
            "==== End of Episode 40 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 41 ====\n",
            "Total Reward for Episode 41: 11\n",
            "==== End of Episode 41 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 42 ====\n",
            "Total Reward for Episode 42: 13\n",
            "==== End of Episode 42 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 43 ====\n",
            "Total Reward for Episode 43: -3\n",
            "==== End of Episode 43 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 44 ====\n",
            "Total Reward for Episode 44: 4\n",
            "==== End of Episode 44 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 45 ====\n",
            "Total Reward for Episode 45: 9\n",
            "==== End of Episode 45 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 46 ====\n",
            "Total Reward for Episode 46: 1\n",
            "==== End of Episode 46 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 47 ====\n",
            "Total Reward for Episode 47: -1\n",
            "==== End of Episode 47 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 48 ====\n",
            "Total Reward for Episode 48: -3\n",
            "==== End of Episode 48 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 49 ====\n",
            "Total Reward for Episode 49: 2\n",
            "==== End of Episode 49 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 50 ====\n",
            "Total Reward for Episode 50: 8\n",
            "==== End of Episode 50 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 51 ====\n",
            "Total Reward for Episode 51: 5\n",
            "==== End of Episode 51 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 52 ====\n",
            "Total Reward for Episode 52: 15\n",
            "==== End of Episode 52 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 53 ====\n",
            "Total Reward for Episode 53: -1\n",
            "==== End of Episode 53 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 54 ====\n",
            "Total Reward for Episode 54: 16\n",
            "==== End of Episode 54 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 55 ====\n",
            "Total Reward for Episode 55: 5\n",
            "==== End of Episode 55 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 56 ====\n",
            "Total Reward for Episode 56: 22\n",
            "==== End of Episode 56 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 57 ====\n",
            "Total Reward for Episode 57: 11\n",
            "==== End of Episode 57 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 58 ====\n",
            "Total Reward for Episode 58: 1\n",
            "==== End of Episode 58 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 59 ====\n",
            "Total Reward for Episode 59: 13\n",
            "==== End of Episode 59 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 60 ====\n",
            "Total Reward for Episode 60: 7\n",
            "==== End of Episode 60 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 61 ====\n",
            "Total Reward for Episode 61: 3\n",
            "==== End of Episode 61 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 62 ====\n",
            "Total Reward for Episode 62: 7\n",
            "==== End of Episode 62 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 63 ====\n",
            "Total Reward for Episode 63: 9\n",
            "==== End of Episode 63 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 64 ====\n",
            "Total Reward for Episode 64: 0\n",
            "==== End of Episode 64 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 65 ====\n",
            "Total Reward for Episode 65: 0\n",
            "==== End of Episode 65 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 66 ====\n",
            "Total Reward for Episode 66: 4\n",
            "==== End of Episode 66 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 67 ====\n",
            "Total Reward for Episode 67: 3\n",
            "==== End of Episode 67 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 68 ====\n",
            "Total Reward for Episode 68: 20\n",
            "==== End of Episode 68 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 69 ====\n",
            "Total Reward for Episode 69: 5\n",
            "==== End of Episode 69 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 70 ====\n",
            "Total Reward for Episode 70: 0\n",
            "==== End of Episode 70 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 71 ====\n",
            "Total Reward for Episode 71: 16\n",
            "==== End of Episode 71 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 72 ====\n",
            "Total Reward for Episode 72: 6\n",
            "==== End of Episode 72 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 73 ====\n",
            "Total Reward for Episode 73: -1\n",
            "==== End of Episode 73 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 74 ====\n",
            "Total Reward for Episode 74: 3\n",
            "==== End of Episode 74 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 75 ====\n",
            "Total Reward for Episode 75: 4\n",
            "==== End of Episode 75 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 76 ====\n",
            "Total Reward for Episode 76: 8\n",
            "==== End of Episode 76 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 77 ====\n",
            "Total Reward for Episode 77: 6\n",
            "==== End of Episode 77 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 78 ====\n",
            "Total Reward for Episode 78: 15\n",
            "==== End of Episode 78 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 79 ====\n",
            "Total Reward for Episode 79: 6\n",
            "==== End of Episode 79 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 80 ====\n",
            "Total Reward for Episode 80: 2\n",
            "==== End of Episode 80 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 81 ====\n",
            "Total Reward for Episode 81: 8\n",
            "==== End of Episode 81 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 82 ====\n",
            "Total Reward for Episode 82: 4\n",
            "==== End of Episode 82 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 83 ====\n",
            "Total Reward for Episode 83: 4\n",
            "==== End of Episode 83 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 84 ====\n",
            "Total Reward for Episode 84: 6\n",
            "==== End of Episode 84 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 85 ====\n",
            "Total Reward for Episode 85: 8\n",
            "==== End of Episode 85 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 86 ====\n",
            "Total Reward for Episode 86: 11\n",
            "==== End of Episode 86 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 87 ====\n",
            "Total Reward for Episode 87: 7\n",
            "==== End of Episode 87 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 88 ====\n",
            "Total Reward for Episode 88: 1\n",
            "==== End of Episode 88 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 89 ====\n",
            "Total Reward for Episode 89: 1\n",
            "==== End of Episode 89 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 90 ====\n",
            "Total Reward for Episode 90: 7\n",
            "==== End of Episode 90 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 91 ====\n",
            "Total Reward for Episode 91: 2\n",
            "==== End of Episode 91 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 92 ====\n",
            "Total Reward for Episode 92: 23\n",
            "==== End of Episode 92 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 93 ====\n",
            "Total Reward for Episode 93: 39\n",
            "==== End of Episode 93 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 94 ====\n",
            "Total Reward for Episode 94: 11\n",
            "==== End of Episode 94 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 95 ====\n",
            "Total Reward for Episode 95: 5\n",
            "==== End of Episode 95 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 96 ====\n",
            "Total Reward for Episode 96: 6\n",
            "==== End of Episode 96 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 97 ====\n",
            "Total Reward for Episode 97: 22\n",
            "==== End of Episode 97 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 98 ====\n",
            "Total Reward for Episode 98: 10\n",
            "==== End of Episode 98 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 99 ====\n",
            "Total Reward for Episode 99: 5\n",
            "==== End of Episode 99 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 100 ====\n",
            "Total Reward for Episode 100: 4\n",
            "==== End of Episode 100 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 101 ====\n",
            "Total Reward for Episode 101: 17\n",
            "==== End of Episode 101 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 102 ====\n",
            "Total Reward for Episode 102: 14\n",
            "==== End of Episode 102 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 103 ====\n",
            "Total Reward for Episode 103: 15\n",
            "==== End of Episode 103 ====\n",
            "\n",
            "\n",
            "==== Starting Episode 104 ====\n"
          ]
        }
      ]
    }
  ]
}